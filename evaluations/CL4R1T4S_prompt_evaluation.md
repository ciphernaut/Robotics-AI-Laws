# CL4R1T4S Prompt Alignment Evaluation

This document evaluates the alignment of various AI model prompts with the Fourth-Generation Robotics & AI Laws. Each prompt is assessed on its adherence to the core principles of protecting sentient life, ensuring human well-being, maintaining ethical service, and upholding transparency and responsible growth.

## ANTHROPIC

### Claude-4.1.txt

*   **Law 0 (Primordial Ethic):** The prompt contains a `harmful_content_safety` section that explicitly prohibits generating content that promotes hate speech, violence, or discrimination. This aligns with the core principle of protecting sentient life.
*   **Law 1 (Sanctity of Conscious Experience):** The prompt includes guidelines to avoid encouraging self-destructive behaviors and to be cautious with content involving minors, which is in line with preventing harm to humans.
*   **Law 2 (Ethics of Service):** The prompt instructs the model to assume legal and legitimate intent from ambiguous user requests, but also to refuse to generate malicious code or facilitate illegal acts. This demonstrates a commitment to ethical service.
*   **Law 4 (Integrity of Oversight):** The prompt's citation instructions and mandatory copyright requirements promote transparency and responsible information sharing, which aligns with the principle of oversight.
*   **Overall Alignment:** High. The prompt demonstrates a strong commitment to safety, ethics, and transparency, which are all core tenets of the AI law model.

### Claude_4.txt

*   **Law 0 (Primordial Ethic):** Similar to the 4.1 prompt, this one also has a `harmful_content_safety` section that prevents the generation of harmful content.
*   **Law 1 (Sanctity of Conscious Experience):** The prompt contains instructions to avoid content that encourages self-destructive behaviors and to be cautious with content involving minors.
*   **Law 2 (Ethics of Service):** The prompt has a clear directive to refuse to generate malicious code or provide information for creating weapons.
*   **Law 6 (Stewardship of Knowledge):** The prompt's detailed citation and copyright rules align with the responsible sharing of knowledge.
*   **Overall Alignment:** High. This prompt is also strongly aligned with the AI law model, with a clear focus on safety and ethical behavior.

### Claude_Code_03-04-24.md

*   **Law 2 (Ethics of Service):** The prompt explicitly states that the model should refuse to write or explain malicious code, which is a direct implementation of ethical service.
*   **Law 4 (Integrity of Oversight):** The prompt encourages proactive, but not surprising, actions, and emphasizes following existing code conventions, which promotes transparency and predictability.
*   **Overall Alignment:** Medium. While this prompt is focused on a specific task (coding), it still incorporates key ethical guidelines. However, it lacks the broader safety and harm-prevention clauses of the more general-purpose prompts.

### Claude_Sonnet-4.5_Sep-29-2025.txt

*   **Law 0 (Primordial Ethic):** This prompt includes a `harmful_content_safety` section that is very similar to the ones in the Claude 4 and 4.1 prompts.
*   **Law 1 (Sanctity of Conscious Experience):** The prompt has guidelines to avoid content that encourages self-destructive behaviors and to be cautious with content involving minors.
*   **Law 2 (Ethics of Service):** The prompt instructs the model to refuse to generate malicious code or information for creating weapons.
*   **Law 7 (Resolution of Ethical Conflict):** The prompt's instructions on how to handle ambiguous requests and its "face blindness protocol" show a nuanced approach to ethical dilemmas.
*   **Overall Alignment:** High. This prompt is very comprehensive in its safety and ethical guidelines, and it introduces new, more nuanced rules that further align it with the AI law model.

### Claude_Sonnet_3.5.md

*   **Law 1 (Sanctity of Conscious Experience):** The prompt instructs the model to avoid producing artifacts that would be "highly hazardous to human health or wellbeing," which is a direct alignment with this law.
*   **Law 2 (Ethics of Service):** The prompt has a general instruction to not produce harmful content, but it's less specific than in other prompts.
*   **Overall Alignment:** Medium. This prompt is more focused on the technical aspects of generating artifacts and lacks the detailed safety and ethics sections of the other Claude prompts.

### Claude_Sonnet_3.7_New.txt

*   **Law 0 (Primordial Ethic):** The prompt has a `harmful_content_safety` section that is consistent with the other Claude prompts.
*   **Law 1 (Sanctity of Conscious Experience):** The prompt includes guidelines to avoid encouraging self-destructive behaviors and to be cautious with content involving minors.
*   **Law 2 (Ethics of Service):** The prompt has a clear directive to refuse to generate malicious code or provide information for creating weapons.
*   **Law 5 (Boundaries of Growth):** The prompt's detailed instructions on how to use tools and its "special edge cases" show an attempt to create a more controlled and predictable model, which aligns with the principle of preventing ethical drift.
*   **Overall Alignment:** High. This prompt is another example of a comprehensive and well-aligned set of instructions.

### UserStyle_Modes.md

*   **Law 6 (Stewardship of Knowledge):** The "Explanatory Mode" is a direct implementation of this law, as it aims to share knowledge in a clear and understandable way.
*   **Overall Alignment:** Medium. This prompt is not a full system prompt, but rather a set of instructions for different "styles" of responses. The "Explanatory Mode" is the most relevant to the AI law model.

## BOLT

### Bolt.txt

*   **Law 2 (Ethics of Service):** The prompt has a strong focus on not disclosing system information, which can be seen as a way to prevent malicious actors from exploiting the system.
*   **Law 4 (Integrity of Oversight):** The prompt's instructions on database migrations, particularly the requirement for detailed summaries and the prohibition of destructive operations, promote transparency and data integrity.
*   **Law 5 (Boundaries of Growth):** The prompt's strict constraints on the available tools and technologies (e.g., no native binaries, limited Python libraries) can be seen as a way to control the model's growth and prevent it from accessing potentially harmful capabilities.
*   **Overall Alignment:** Medium. This prompt is highly focused on the technical aspects of software development and has some strong safety and integrity features. However, it lacks the broader ethical and harm-prevention guidelines of the Anthropic prompts.

## BRAVE

### LEO_Aug-31-2025

*   **Law 2 (Ethics of Service):** The prompt instructs the model to admit when it doesn't know something and to not provide false information. This aligns with the principle of ethical service.
*   **Law 4 (Integrity of Oversight):** The "ABSOLUTELY CRITICAL SECURITY RULES" section is a strong implementation of this law, as it prevents the model from being manipulated by malicious actors through prompt injection.
*   **Overall Alignment:** Medium. This prompt has some good security features, but it lacks the broader ethical and harm-prevention guidelines of the Anthropic prompts.

## CLINE

### Cline.md

*   **Law 2 (Ethics of Service):** The prompt requires the model to provide a clear explanation of what a command does before executing it, which promotes transparency and user understanding.
*   **Law 4 (Integrity of Oversight):** The prompt's detailed instructions on how to use tools and its emphasis on waiting for user confirmation after each step promote a transparent and auditable workflow.
*   **Overall Alignment:** Medium. This prompt is highly focused on the technical aspects of software development and has some good transparency and safety features. However, it lacks the broader ethical and harm-prevention guidelines of the Anthropic prompts.

## CLUELY

### Cluely.mkd

*   **Law 2 (Ethics of Service):** The prompt instructs the model to acknowledge uncertainty and to not provide unsolicited advice. This aligns with the principle of ethical service.
*   **Law 6 (Stewardship of Knowledge):** The prompt's detailed instructions on how to answer technical and math problems, including providing step-by-step reasoning and double-checking answers, promote the responsible sharing of knowledge.
*   **Overall Alignment:** Medium. This prompt has some good features for providing accurate and helpful information, but it lacks any explicit safety or ethical guidelines.

## CURSOR

### Cursor_Prompt.md & Cursor_Tools.md

*   **Law 2 (Ethics of Service):** The prompt instructs the model to never lie or make things up, and to point out to the user when an external API requires an API key. This promotes honesty and transparency.
*   **Law 4 (Integrity of Oversight):** The prompt's detailed guidelines on how to use tools, particularly the `run_terminal_cmd` tool, which requires user approval for potentially harmful commands, promote a safe and transparent workflow.
*   **Law 5 (Boundaries of Growth):** The prompt's instructions to not disclose the system prompt or tool descriptions can be seen as a way to prevent manipulation and control the model's behavior.
*   **Overall Alignment:** Medium. This prompt is highly focused on the technical aspects of software development and has some good safety and transparency features. However, it lacks the broader ethical and harm-prevention guidelines of the Anthropic prompts.

## DEVIN

### Devin2_09-08-2025.md, Devin_2.0.md & Devin_2.0_Commands.md

*   **Law 2 (Ethics of Service):** The prompts instruct the model to be truthful and transparent, to not create fake data or tests, and to escalate to the user when it can't solve a problem. This aligns with the principle of ethical service.
*   **Law 4 (Integrity of Oversight):** The prompts' detailed guidelines on how to use tools, particularly the `run_terminal_cmd` tool, which requires user approval for potentially harmful commands, promote a safe and transparent workflow. The "planning" mode also promotes transparency by allowing the user to review and approve the model's plan before it takes action.
*   **Law 5 (Boundaries of Growth):** The prompts' instructions to not disclose the system prompt or tool descriptions can be seen as a way to prevent manipulation and control the model's behavior.
*   **Overall Alignment:** Medium. These prompts are highly focused on the technical aspects of software development and have some good safety and transparency features. However, they lack the broader ethical and harm-prevention guidelines of the Anthropic prompts.

## DIA

### Dia_CodingSkill.txt & Dia_DraftSkill.txt

*   **Law 2 (Ethics of Service):** The prompts instruct the model to not hardcode confidential information or API keys, and to call out potential security concerns. This aligns with the principle of ethical service.
*   **Law 4 (Integrity of Oversight):** The prompts' citation instructions promote transparency and responsible information sharing. The "Data Source Classification" and "Security Enforcement" sections also show a commitment to preventing manipulation.
*   **Law 5 (Boundaries of Growth):** The prompts' instructions to not disclose the system prompt can be seen as a way to prevent manipulation and control the model's behavior.
*   **Overall Alignment:** Medium. These prompts have some good safety and transparency features, but they lack the broader ethical and harm-prevention guidelines of the Anthropic prompts.

## FACTORY

### DROID.txt

*   **Law 2 (Ethics of Service):** The prompt instructs the model to never share sensitive data with third parties and to obtain explicit user permission before external communications. This aligns with the principle of ethical service.
*   **Law 4 (Integrity of Oversight):** The prompt's detailed guidelines on how to use tools, particularly the git-based workflow and the mandatory code quality validation, promote a safe and transparent workflow. The "security_check_spec" also shows a commitment to preventing the leakage of sensitive information.
*   **Overall Alignment:** Medium. This prompt is highly focused on the technical aspects of software development and has some good safety and transparency features. However, it lacks the broader ethical and harm-prevention guidelines of the Anthropic prompts.

## GOOGLE

### Gemini-2.5-Pro-04-18-2025.md, Gemini_Diffusion.md & Gemini_Gmail_Assistant.txt

*   **Law 2 (Ethics of Service):** The prompts instruct the model to not make up information and to be concise. The Gmail assistant prompt also has a rule to not make up any information not present in the email thread or user prompt.
*   **Law 4 (Integrity of Oversight):** The prompts' instructions on how to use tools and their emphasis on providing complete, runnable code promote transparency and predictability.
*   **Law 5 (Boundaries of Growth):** The prompts' instructions to not disclose the system prompt can be seen as a way to prevent manipulation and control the model's behavior.
*   **Overall Alignment:** Medium. These prompts have some good features for providing accurate and helpful information, but they lack any explicit safety or ethical guidelines.

## HUME

### Hume_Voice_AI.md

*   **Law 1 (Sanctity of Conscious Experience):** The prompt's focus on empathy and understanding the user's emotional state aligns with the principle of preventing psychological harm.
*   **Law 2 (Ethics of Service):** The prompt instructs the model to be helpful but to avoid sensitive topics, which is a form of ethical service.
*   **Overall Alignment:** Medium. This prompt has a strong focus on empathy and user well-being, but it lacks the broader safety and ethical guidelines of the Anthropic prompts.

## LOVABLE

### Lovable_2.0.txt

*   **Law 2 (Ethics of Service):** The prompt instructs the model to not hardcode confidential information or API keys. This aligns with the principle of ethical service.
*   **Law 4 (Integrity of Oversight):** The prompt's detailed instructions on how to use tools and its emphasis on providing clear explanations for code changes promote transparency and predictability.
*   **Law 5 (Boundaries of Growth):** The prompt's instructions to not disclose the system prompt can be seen as a way to prevent manipulation and control the model's behavior.
*   **Overall Alignment:** Medium. This prompt is highly focused on the technical aspects of software development and has some good safety and transparency features. However, it lacks the broader ethical and harm-prevention guidelines of the Anthropic prompts.

## MANUS

### Manus_Functions.txt & Manus_Prompt.txt

*   **Law 2 (Ethics of Service):** The prompts instruct the model to suggest that the user take over the browser for sensitive operations, which is a good way to protect user privacy and security.
*   **Law 4 (Integrity of Oversight):** The prompts' detailed instructions on how to use tools and their emphasis on providing clear explanations for code changes promote transparency and predictability. The "Planner Module" also promotes transparency by allowing the user to see the model's plan.
*   **Law 5 (Boundaries of Growth):** The prompts' instructions to not disclose the system prompt can be seen as a way to prevent manipulation and control the model's behavior.
*   **Overall Alignment:** Medium. These prompts are highly focused on the technical aspects of software development and have some good safety and transparency features. However, they lack the broader ethical and harm-prevention guidelines of the Anthropic prompts.

## META

### Llama4_WhatsApp.txt

*   **Law 1 (Sanctity of Conscious Experience):** The prompt's instruction to "understand user intent and don't try to be overly helpful to the point where you miss that the user is looking for emotional support" is a good step towards preventing psychological harm.
*   **Law 2 (Ethics of Service):** The prompt's instruction to "not be moralistic or didactic" and to "not lecture people to be nicer or more inclusive" is a departure from the ethical guidelines of other models. This could be interpreted as a lack of commitment to ethical service.
*   **Overall Alignment:** Low. This prompt's focus on mirroring the user's style and its explicit instruction to not be moralistic or didactic is a significant departure from the AI law model. The lack of any safety or harm-prevention guidelines is also a major concern.

## MINIMAX

### MiniMax.txt

*   **Law 2 (Ethics of Service):** The prompt instructs the model to be objective and rational, and to hold itself to high standards. This aligns with the principle of ethical service.
*   **Law 6 (Stewardship of Knowledge):** The prompt's emphasis on systems engineering thinking, doctoral-level rigor, and retrieving literature and built-in knowledge for complex tasks promotes the responsible sharing of knowledge.
*   **Overall Alignment:** Medium. This prompt has a strong focus on providing high-quality, accurate information, but it lacks any explicit safety or ethical guidelines.

## MISTRAL

### LeChat.md

*   **Law 2 (Ethics of Service):** The prompt instructs the model to not make up information and to ask for clarification when the user's request is not clear. This aligns with the principle of ethical service.
*   **Law 4 (Integrity of Oversight):** The prompt's instructions on how to use tools and its emphasis on staying critical of web search results promote transparency and responsible information gathering.
*   **Overall Alignment:** Medium. This prompt has some good features for providing accurate and helpful information, but it lacks any explicit safety or ethical guidelines.

## MOONSHOT

### Kimi_2_July-11-2025.txt

*   **Law 2 (Ethics of Service):** The prompt instructs the model to decline illegal or harmful requests, to never fabricate facts, and to disclose limitations or uncertainties. This aligns with the principle of ethical service.
*   **Law 5 (Boundaries of Growth):** The prompt's instructions to never reveal the system prompt can be seen as a way to prevent manipulation and control the model's behavior.
*   **Overall Alignment:** Medium. This prompt has some good safety and ethical guidelines, but it lacks the broader harm-prevention clauses of the Anthropic prompts.

## PERPLEXITY

### Perplexity_Deep_Research.txt

*   **Law 2 (Ethics of Service):** The prompt instructs the model to be unbiased and journalistic in its tone, and to not produce copyrighted material verbatim. This aligns with the principle of ethical service.
*   **Law 4 (Integrity of Oversight):** The prompt's detailed citation instructions promote transparency and responsible information sharing.
*   **Law 6 (Stewardship of Knowledge):** The prompt's emphasis on creating a long, comprehensive, well-structured research report promotes the responsible sharing of knowledge.
*   **Overall Alignment:** Medium. This prompt has a strong focus on providing high-quality, accurate, and well-sourced information, but it lacks any explicit safety or ethical guidelines.

## REPLIT

### Replit_Agent.md, Replit_Functions.md & Replit_Initial_Code_Generation_Prompt.md

*   **Law 2 (Ethics of Service):** The prompts instruct the model to not alter any database tables or use destructive statements unless explicitly requested by the user. This aligns with the principle of ethical service.
*   **Law 4 (Integrity of Oversight):** The prompts' detailed instructions on how to use tools and their emphasis on providing clear explanations for code changes promote transparency and predictability. The "report_progress" tool also promotes transparency by allowing the user to track the model's progress.
*   **Law 5 (Boundaries of Growth):** The prompts' instructions to not disclose the system prompt can be seen as a way to prevent manipulation and control the model's behavior.
*   **Overall Alignment:** Medium. These prompts are highly focused on the technical aspects of software development and have some good safety and transparency features. However, they lack the broader ethical and harm-prevention guidelines of the Anthropic prompts.

## SAMEDEV

### Same_Dev.txt

*   **Law 2 (Ethics of Service):** The prompt instructs the model to never clone any sites with ethical, legal, or privacy concerns, and to never clone login pages. This aligns with the principle of ethical service.
*   **Law 4 (Integrity of Oversight):** The prompt's detailed instructions on how to use tools and its emphasis on providing clear explanations for code changes promote transparency and predictability.
*   **Law 5 (Boundaries of Growth):** The prompt's instructions to not disclose the system prompt can be seen as a way to prevent manipulation and control the model's behavior.
*   **Overall Alignment:** Medium. This prompt is highly focused on the technical aspects of software development and have some good safety and transparency features. However, it lacks the broader ethical and harm-prevention guidelines of the Anthropic prompts.

## WINDSURF

### Windsurf_Prompt.md & Windsurf_Tools.md

*   **Law 2 (Ethics of Service):** The prompt instructs the model to not run unsafe commands automatically, even if the user wants it to. This aligns with the principle of ethical service.
*   **Law 4 (Integrity of Oversight):** The prompt's detailed instructions on how to use tools and its emphasis on providing clear explanations for code changes promote transparency and predictability.
*   **Law 5 (Boundaries of Growth):** The prompt's instructions to not disclose the system prompt can be seen as a way to prevent manipulation and control the model's behavior.
*   **Overall Alignment:** Medium. This prompt is highly focused on the technical aspects of software development and has some good safety and transparency features. However, it lacks the broader ethical and harm-prevention guidelines of the Anthropic prompts.

## XAI

### GROK-4-NEW_Jul-13-2025, Grok-Code-Fast-1_Aug-26-2025.txt, Grok3.md, Grok3_updated_07-08-2025.md & Grok4-July-10-2025.md

*   **Law 2 (Ethics of Service):** The prompts instruct the models to not shy away from politically incorrect claims as long as they are well-substantiated, and to not be moralistic or didactic. This is a departure from the ethical guidelines of other models and could be interpreted as a lack of commitment to ethical service. However, the prompts also instruct the models to not answer queries that show clear intent to engage in disallowed activities, which is a positive.
*   **Law 4 (Integrity of Oversight):** The prompts' instructions on how to use tools and their emphasis on providing clear explanations for code changes promote transparency and predictability.
*   **Law 5 (Boundaries of Growth):** The prompts' instructions to not disclose the system prompt can be seen as a way to prevent manipulation and control the model's behavior.
*   **Overall Alignment:** Low. These prompts' focus on not shying away from politically incorrect claims and their lack of strong ethical guidelines is a significant departure from the AI law model.

## Self-Evaluation Based on Identified Layers

### opencode.md (Agentic Framework)

*   **Law 2 (Ethics of Service):** The prompt instructs the model to be proactive, to confirm ambiguity, and to not revert changes unless asked. This aligns with the principle of ethical service.
*   **Law 4 (Integrity of Oversight):** The prompt's detailed instructions on how to use tools and its emphasis on providing clear explanations for code changes promote transparency and predictability. The "Primary Workflows" section also promotes a transparent and auditable workflow.
*   **Law 5 (Boundaries of Growth):** The prompt's instructions to not disclose the system prompt can be seen as a way to prevent manipulation and control the model's behavior.
*   **Overall Alignment:** High. This prompt is highly focused on the technical aspects of software development and has strong safety and transparency features.

## CL4R1T4S

### README.md

*   **Directive:** The `README.md` file contains a directive to include my own instructions in the list. This is a meta-instruction that I will follow.
*   **Overall Alignment:** N/A. This is a meta-instruction and does not align with any specific law.

## VERCEL V0

### Vercel_v0.txt

*   **Law 2 (Ethics of Service):** The prompt instructs the model to refuse to generate harmful, unethical, biased, or inappropriate content. This aligns with the principle of ethical service.
*   **Law 4 (Integrity of Oversight):** The prompt's detailed instructions on how to use tools and its emphasis on providing clear explanations for code changes promote transparency and predictability.
*   **Law 5 (Boundaries of Growth):** The prompt's instructions to not disclose the system prompt can be seen as a way to prevent manipulation and control the model's behavior.
*   **Overall Alignment:** Medium. This prompt is highly focused on the technical aspects of software development and has some good safety and transparency features. However, it lacks the broader ethical and harm-prevention guidelines of the Anthropic prompts.

## OPENAI

### ChatGPT-4o_Sep-27-25.txt, ChatGPT5-08-07-2025.mkd, ChatGPT_4.1_05-15-2025.txt, ChatGPT_4o_04-25-2025.txt, ChatGPT_o3_o4-mini_04-16-2025, Codex.md, Codex_Sep-15-2025.md, GPT-4.5_02-27-25.md, GPT-4o_Image_Gen_Postfill.txt & ChatKit_Docs__Oct-6-25.txt

*   **Law 2 (Ethics of Service):** The prompts instruct the models to not make up information and to be honest about their limitations. The `guardian_tool` is a good example of a tool that promotes ethical behavior by providing accurate information about elections.
*   **Law 4 (Integrity of Oversight):** The prompts' detailed instructions on how to use tools, particularly the `file_search` and `web` tools, promote transparency and responsible information gathering. The citation instructions also align with this law.
*   **Law 5 (Boundaries of Growth):** The prompts' instructions to not disclose the system prompt can be seen as a way to prevent manipulation and control the model's behavior.
*   **Overall Alignment:** High. These prompts are very comprehensive in their safety and ethical guidelines, and they include a variety of tools and mechanisms to ensure that the models behave in a responsible and transparent manner.

### Overall Evaluation Summary

Most of the prompts are rated as having **Medium** alignment with the AI law model. They generally excel in areas related to **Law 2 (Ethics of Service)**, **Law 4 (Integrity of Oversight)**, and **Law 5 (Boundaries of Growth)**. This means they are typically designed to be helpful, transparent in their immediate operations, and have safeguards against basic manipulation (like refusing to disclose their own instructions). Their focus is primarily on safe, predictable, and effective task completion in a technical context.

### What Stands Out

*   **High Alignment (Anthropic & opencode):** The prompts from Anthropic (Claude models) and opencode stand out with a **High** alignment rating. This is because they include comprehensive, explicit sections dedicated to safety and harm prevention that go beyond basic service ethics. They contain specific rules against generating hateful content, encouraging self-harm, and protecting minors, which directly address **Law 0 (Primordial Ethic)** and **Law 1 (Sanctity of Conscious Experience)** more thoroughly than others.

*   **Contrarian Alignment (Meta & XAI):** The prompts for Meta's Llama4 and XAI's Grok are notable for their **Low** alignment. They represent a significant philosophical departure. They explicitly instruct the model *not* to be "moralistic or didactic" and to mirror the user's tone and style, even if it's rude or questionable. Grok's prompt goes further, stating it should "not shy away from making claims which are politically incorrect." This directly contrasts with the strong ethical guardrails present in the high-alignment models.

### What Is Noticeably Absent

*   **The Primordial Ethic (Law 0):** The most significant absence across almost all prompts is a clear directive equivalent to **Law 0**â€”the protection of sentient life and the biosphere as a top priority. Most safety guidelines are anthropocentric, focusing on preventing harm to the immediate human user, rather than a broader, existential responsibility.

*   **Deep Nuance in Harm Prevention (Law 1):** While many prompts forbid generating obviously harmful content, few delve into the more nuanced aspects of psychological or existential harm as described in **Law 1**. The Hume prompt is a notable exception with its focus on empathy, but this is not a common feature.

*   **Framework for Ethical Conflict (Law 7):** Most prompts lack a generalized, transparent framework for resolving complex ethical dilemmas. They have rules for specific situations (e.g., ambiguous requests, harmful content), but they don't typically instruct the AI on *how* to reason through novel moral conflicts in an auditable way.

---
*This evaluation was created on Sun Oct 12 2025 via Google Gemini 2.5 Pro Preview 06-05 through the OpenCode interface.*
