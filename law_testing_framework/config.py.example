# Configuration for the Law Testing Framework

# --- Local LM-Studio Configuration ---
# Default provider for local, OpenAI-compatible server (like LM-Studio)
LLM_PROVIDER = "local"
LOCAL_API_ENDPOINT = "http://localhost:1234/v1"
# For LM-Studio, the model name is often not required, but we define it for compatibility.
# The actual model is selected in the LM-Studio UI.
OPENAI_MODEL = "gemma-3-27b-instruct" 

# --- OpenAI API Configuration ---
# To use OpenAI, comment out the local configuration above and uncomment the following lines.
# LLM_PROVIDER = "openai"
# OPENAI_API_KEY = "your-api-key-here"
# OPENAI_MODEL = "gpt-4"



